# -*- coding: utf-8 -*-
"""Lime(crop).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-2_dyrE8WNlv4x8_Vo-QmPAhXsdzAdK7
"""





!pip install lime
import lime
import lime.lime_tabular
import numpy as np
import pandas as pd
import joblib
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Load dataset
df = pd.read_csv("crop_price_prediction_data.csv")

# Encode categorical features
label_cols = ['State', 'City', 'Crop Type', 'Month', 'Season']
df[label_cols] = df[label_cols].apply(LabelEncoder().fit_transform)

# Convert price into category
df['price_category'] = pd.qcut(df['price(ton)'], q=3, labels=['Low', 'Medium', 'High'])

# Define features and target
X = df.drop(columns=['Date', 'price(ton)', 'price_category'])
y = df['price_category']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#LIME with Random Forest
# Train a model (example: Random Forest)
rf_model = RandomForestClassifier()
rf_model.fit(X_train_scaled, y_train)

# Create LIME explainer
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_train_scaled,
    feature_names=X.columns,
    class_names=['Low', 'Medium', 'High'],
    mode='classification'
)

# Explain a single prediction
i = 5  # Index of test sample to explain
exp = explainer.explain_instance(X_test_scaled[i], rf_model.predict_proba, num_features=10)

# Show explanation in notebook
exp.show_in_notebook(show_table=True)

# OR, save explanation as HTML
exp.save_to_file('lime_explanation.html')

# LIME with Logistic Regression
logreg_model = LogisticRegression(max_iter=1000)
logreg_model.fit(X_train_scaled, y_train)

explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train_scaled, feature_names=X.columns, class_names=['Low', 'Medium', 'High'], mode='classification'
)

exp = explainer.explain_instance(X_test_scaled[3], logreg_model.predict_proba, num_features=8)
exp.show_in_notebook(show_table=True)

from sklearn.svm import SVC

#LIME with Support Vector Machine (SVM)
svm_model = SVC(max_iter=1000)
svm_model.fit(X_train_scaled, y_train)

explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train_scaled, feature_names=X.columns, class_names=['Low', 'Medium', 'High'], mode='classification'
)

exp = explainer.explain_instance(X_test_scaled[3], logreg_model.predict_proba, num_features=8)
exp.show_in_notebook(show_table=True)

!pip install lime

#LIME with Decision tree
from sklearn.tree import DecisionTreeClassifier
destree_model = DecisionTreeClassifier()  # Remove max_iter
destree_model.fit(X_train_scaled, y_train)

explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train_scaled, feature_names=X.columns, class_names=['Low', 'Medium', 'High'], mode='classification'
)

exp = explainer.explain_instance(X_test_scaled[3], destree_model.predict_proba, num_features=8) # Use destree_model here
exp.show_in_notebook(show_table=True)







